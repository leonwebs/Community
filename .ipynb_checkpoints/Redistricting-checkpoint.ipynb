{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Districts that preserve \"communities of interest\"\n",
    "\n",
    "\n",
    "First we import our libraries and load the data files.  We'll use\n",
    "census demographic data to quantify the community of interest.\n",
    "Keeping the scope narrow, we'll just examine race and ethnicity, but\n",
    "income, education level, or other indicators may be used.  We also\n",
    "load current districts to evaluate how well they preserve communities\n",
    "of interest.  When the redistricting commission produces new\n",
    "districts, they may be evaluated, too.  Finally, we include census\n",
    "data by county, which can validate our code more quickly because it\n",
    "has many fewer areas to cluster.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysal\\__init__.py:65: VisibleDeprecationWarning: PySAL's API will be changed on 2018-12-31. The last release made with this API is version 1.14.4. A preview of the next API version is provided in the `pysalnext` package. The API changes and a guide on how to change imports is provided at https://migrating.pysal.org\n",
      "  ), VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pysal as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import region\n",
    "\n",
    "\n",
    "def loaddata(filename, url):\n",
    "    if not(os.path.isfile(filename+'.geojson')):\n",
    "        print(\"Retrieving the data and storing to a file\")\n",
    "    #    req = requests.get(url, filename)\n",
    "    #    tractdat = req.json()\n",
    "    #    geojson knows how to read urls, so no need for requests module\n",
    "        geodat = gpd.read_file(url)\n",
    "        geodat.to_file(filename + '.geojson', driver='GeoJSON')\n",
    "        geodat.to_file(filename)\n",
    "    else:\n",
    "        geodat = gpd.read_file(filename)\n",
    "    #convert all to numeric where possible\n",
    "    geodat = geodat.apply(pd.to_numeric, errors = 'ignore')\n",
    "    #'pop' is not a good name for population\n",
    "    if 'pop' in geodat.columns:\n",
    "        geodat.rename({'pop':'population'}, axis = 'columns', inplace = True)\n",
    "\n",
    "    return geodat\n",
    "#tractdat.plot()\n",
    "tractdat = loaddata('censustracts17','https://data.colorado.gov/resource/aevh-apr2.geojson?$limit=1300')\n",
    "countydat = loaddata('censuscounties17','https://data.colorado.gov/resource/ewkj-ipn7.geojson')\n",
    "currentdist = loaddata('censusdist','https://data.colorado.gov/resource/jz4n-qus2.geojson') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are missing data; the medians sometimes not defined for a\n",
    "tract.  For now we won't use columns without data and later go back\n",
    "and deal with nans using perhaps `DataFrame.fillna()`.  To start we'll\n",
    "limit our analysis to communnities of interest defined by race and\n",
    "ethnicity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns have nan elements\n",
      "['med_age', 'med_fam_in', 'med_g_rent', 'avghhsize', 'med_hm_val', 'med_c_rent', 'med_hh_inc', 'med_yr_blt', 'per_cap_in']\n"
     ]
    }
   ],
   "source": [
    "print('The following columns have nan elements')\n",
    "badcol = tractdat.columns[tractdat.isnull().any()]\n",
    "print(list(badcol))\n",
    "\n",
    "\n",
    "racecat = [ 'hispanic', 'white_nh', 'black_nh', 'ntvam_nh', 'asian_nh', 'hawpi_nh', 'other_nh', 'twoplus_nh']\n",
    "#agecat = [i for i in tractdat.columns if 'age' in i and i not in badcol]\n",
    "#incomecat = []\n",
    "#all income categories have some nans!\n",
    "#educationcat = [i for i in tractdat.columns if 'gr' in i and i not in badcol]\n",
    "#educationcat.extend(['enrolled', 'n_enrolled'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'd like to answer the question \"Where are the communities?\"\n",
    "The `max-p` algorithm divides a set of areas into regions with similar\n",
    "characteristicts.  The number of regions is not set, but is chosen by\n",
    "the algorithm to optimize intra-region similarity.  It does require a\n",
    "minimum value for each region, in this case we'll say that each region\n",
    "requires at least 250,000 people, about 5% of the state.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning maxp regionalization ...\n"
     ]
    }
   ],
   "source": [
    "w = ps.queen_from_shapefile('censustracts17/censustracts17.shp', idVariable = 'geonum')\n",
    "#w = ps.queen_from_shapefile('censuscounties17/censuscounties17.shp', idVariable = 'geonum')\n",
    "\n",
    "z = tractdat[racecat].values\n",
    "#z = countydat[racecat].values\n",
    "\n",
    "print(\"Beginning maxp regionalization ...\")\n",
    "maxp = ps.region.Maxp(w, z, 500000 , tractdat.population, initial=300)\n",
    "#maxp = ps.region.Maxp(w, z, 500000 , countydat.population, initial=300)\n",
    "print(\"... done.\")\n",
    "\n",
    "lbls = pd.Series(maxp.area2region).reindex(tractdat['geonum'])\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "#countydat.assign(cl=lbls.values).plot(column='cl',\n",
    "tractdat.assign(cl=lbls.values).plot(column='cl',\n",
    "                                     categorical=True,\n",
    "                                     legend=True,\n",
    "                                     linewidth=0.1,\n",
    "                                     edgecolor='white',\n",
    "                                     ax=ax)\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course these cannot be congressional districts.  There must be only\n",
    "7 districts, one for each seat Colorado has in the House of\n",
    "Representatives.  In addition, there must be close to equal population\n",
    "in each district.  \n",
    "\n",
    "Now we will use the AZP algorithm to generate a specific number of\n",
    "districts.  The algorithm optimizes an objective function, which in this\n",
    "case includes intra-region similarity and total population.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning regionalization ...\n",
      "n_regions_per_comp {0: 7}\n",
      "comp_label 0\n",
      "n_regions_in_comp 7\n",
      "Regions in comp: {0, 1, 2, 3, 4, 5, 6}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4fc16f842b0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m pregazp.fit_from_geodataframe(tractdat, ['population']+racecat, \n\u001b[0;32m      8\u001b[0m                               \u001b[0mndist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontiguity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"queen\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                               objective_func = region.objective_function.ObjectiveFunctionPairwiseWithTotal() )\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"... done.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtractdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtractdat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpopweightfactor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\src\\region\\region\\p_regions\\azp.py\u001b[0m in \u001b[0;36mfit_from_geodataframe\u001b[1;34m(self, gdf, attr, n_regions, contiguity, initial_labels, objective_func)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_from_df_col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         self.fit_from_w(\n\u001b[1;32m--> 238\u001b[1;33m             w, attr, n_regions, initial_labels, objective_func=objective_func)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     def fit_from_dict(self,\n",
      "\u001b[1;32mc:\\windows\\system32\\src\\region\\region\\p_regions\\azp.py\u001b[0m in \u001b[0;36mfit_from_w\u001b[1;34m(self, w, attr, n_regions, initial_labels, objective_func)\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[0mn_regions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[0minitial_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             objective_func=objective_func)\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     def fit_from_networkx(self,\n",
      "\u001b[1;32mc:\\windows\\system32\\src\\region\\region\\p_regions\\azp.py\u001b[0m in \u001b[0;36mfit_from_scipy_sparse_matrix\u001b[1;34m(self, adj, attr, n_regions, initial_labels, objective_func)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             labels_comp = self._azp_connected_component(\n\u001b[1;32m--> 106\u001b[1;33m                 adj_comp, labels_comp, attr_comp)\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcomp_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_comp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\src\\region\\region\\p_regions\\azp.py\u001b[0m in \u001b[0;36m_azp_connected_component\u001b[1;34m(self, adj, initial_clustering, attr)\u001b[0m\n\u001b[0;32m    350\u001b[0m                             \u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mneigh_region\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                             wo_nodes=neigh)\n\u001b[0m\u001b[0;32m    353\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mis_connected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_adj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                             \u001b[1;31m# if area is alone in its region, it must stay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\windows\\system32\\src\\region\\region\\csgraph_utils.py\u001b[0m in \u001b[0;36msub_adj_matrix\u001b[1;34m(adj, nodes, wo_nodes)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    348\u001b[0m         csr_sample_values(self.shape[0], self.shape[1],\n\u001b[0;32m    349\u001b[0m                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m                           num_samples, row.ravel(), col.ravel(), val)\n\u001b[0m\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m             \u001b[1;31m# row and col are 1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ndist = 7\n",
    "popweightfactor=1\n",
    "tractdat.population = tractdat.population*popweightfactor\n",
    "\n",
    "pregazp = region.p_regions.azp.AZP()\n",
    "print(\"Beginning regionalization ...\")\n",
    "pregazp.fit_from_geodataframe(tractdat, ['population']+racecat, \n",
    "                              ndist, contiguity = \"queen\", \n",
    "                              objective_func = region.objective_function.ObjectiveFunctionPairwiseWithTotal() )\n",
    "print(\"... done.\")\n",
    "tractdat.population = tractdat.population/popweightfactor\n",
    "\n",
    "f, ax = plt.subplots(1, figsize=(9,9))\n",
    "ctylabeled = tractdat.assign(cl = pregazp.labels_)\n",
    "ctylabeled.plot(column = 'cl', \n",
    "                categorical = True, \n",
    "                legend = True, \n",
    "                linewidth = .1, \n",
    "                edgecolor = 'white', \n",
    "                ax = ax)\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
